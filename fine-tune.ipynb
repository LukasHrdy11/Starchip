{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luk-hrd/miniconda3/envs/mistral-lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Konfigurace ---\n",
    "# Cesta k vašemu lokálně uloženému modelu\n",
    "MODEL_PATH = \"/home/luk-hrd/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe\"\n",
    "\n",
    "# Název datasetu na Hugging Face Hubu\n",
    "DATASET_NAME = \"BoltzmannEntropy/QuantumLLMInstruct\"\n",
    "\n",
    "# Název pro váš nový, fine-tunovaný model (pro výstupní adresář)\n",
    "NEW_MODEL_NAME = \"mistral-7b-quantum-instruct-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Příklad naformátovaného promptu:\n",
      "[INST] You are an expert in 'Quantum Thermodynamics', specifically focusing on 'QUANTUM THERMODYNAMICS'. Provide a detailed, step-by-step solution to the following problem:\n",
      "\n",
      "### Problem:\n",
      "Consider a two-qubit system initially prepared in the state \\( |\\psi_0\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}} \\). The Hamiltonian of the system is given by \\( H = \\sigma_1^z \\sigma_2^z \\), where \\( \\sigma_i^z \\) is the Pauli z-operator for qubit \\( i \\). The system is then allowed to evolve under the dynamics of the Hamiltonian for a time \\( t = \\pi \\). Calculate the von Neumann entropy of the system at \\( t = \\pi \\). [/INST] To solve this problem, we need to follow these steps:\n",
      "\n",
      "1. **Express the initial state in matrix form:**\n",
      "   The initial state \\( |\\psi_0\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}} \\) can be written in matrix form as:\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n",
      "   \\]\n",
      "\n",
      "2. **Define the Pauli z-operators:**\n",
      "   The Pauli z-operators for qubits 1 and 2 are:\n",
      "   \\[\n",
      "   \\sigma_1^z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad \\sigma_2^z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n",
      "   \\]\n",
      "   The Hamiltonian \\( H \\) is given by:\n",
      "   \\[\n",
      "   H = \\sigma_1^z \\sigma_2^z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
      "   \\]\n",
      "\n",
      "3. **Find the eigenvalues and eigenvectors of the Hamiltonian:**\n",
      "   The eigenvalues of \\( H \\) are:\n",
      "   \\[\n",
      "   E_1 = 1, \\quad E_2 = 1\n",
      "   \\]\n",
      "   The corresponding eigenvectors are:\n",
      "   \\[\n",
      "   |+\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad |-\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n",
      "   \\]\n",
      "\n",
      "4. **Express the initial state in the basis of the eigenvectors of the Hamiltonian:**\n",
      "   We can write:\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\alpha |+\\rangle + \\beta |-\\rangle\n",
      "   \\]\n",
      "   Using the initial state \\( |\\psi_0\\rangle = \\frac{1}{\\sqrt{2}} (|00\\rangle + |11\\rangle) \\), we can express it in terms of the basis vectors:\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\frac{1}{\\sqrt{2}} \\left( \\frac{1}{\\sqrt{2}} (|0\\rangle + |1\\rangle) \\otimes |0\\rangle + \\frac{1}{\\sqrt{2}} (|0\\rangle + |1\\rangle) \\otimes |1\\rangle \\right)\n",
      "   \\]\n",
      "   This simplifies to:\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\frac{1}{2} \\left( |00\\rangle + |01\\rangle + |10\\rangle + |11\\rangle \\right)\n",
      "   \\]\n",
      "   In terms of the basis \\( |+\\rangle \\) and \\( |-\\rangle \\):\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\frac{1}{2} \\left( \\frac{1}{\\sqrt{2}} (|+\\rangle + |-\\rangle) \\otimes |0\\rangle + \\frac{1}{\\sqrt{2}} (|+\\rangle - |-\\rangle) \\otimes |1\\rangle \\right)\n",
      "   \\]\n",
      "   This can be written as:\n",
      "   \\[\n",
      "   |\\psi_0\\rangle = \\frac{1}{2} (|+\\rangle \\otimes |0\\rangle + |-\\rangle \\otimes |1\\rangle)\n",
      "   \\]\n",
      "   Therefore, we have:\n",
      "   \\[\n",
      "   \\alpha = \\frac{1}{2}, \\quad \\beta = \\frac{1}{2}\n",
      "   \\]\n",
      "\n",
      "5. **Evolve the state under the Hamiltonian for time \\( t = \\pi \\):**\n",
      "   The state after time \\( t = \\pi \\) is given by:\n",
      "   \\[\n",
      "   |\\psi(t)\\rangle = e^{-iHt} |\\psi_0\\rangle\n",
      "   \\]\n",
      "   Since \\( H = I \\), the evolution operator \\( e^{-iHt} = e^{-iI\\pi} = (-1)^{\\pi} = -1 \\). Therefore:\n",
      "   \\[\n",
      "   |\\psi(\\pi)\\rangle = -|\\psi_0\\rangle = -\\frac{1}{\\sqrt{2}} (|00\\rangle + |11\\rangle)\n",
      "   \\]\n",
      "\n",
      "6.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Načtení a příprava datasetu ---\n",
    "\n",
    "# Načteme pouze trénovací split datasetu\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "\n",
    "# Vylepšená formátovací funkce, která přidává kontext z dalších sloupců\n",
    "def format_prompt_with_context(sample):\n",
    "    # Bezpečné načtení hodnot, pokud by chyběly\n",
    "    main_domain = sample.get('main_domain', 'quantum computing')\n",
    "    sub_domain = sample.get('sub_domain', 'a specific topic')\n",
    "    problem = sample['problem']\n",
    "    solution = sample['solution']\n",
    "    \n",
    "    # Vytvoření bohatší a specifičtější instrukce\n",
    "    instruction = (\n",
    "        f\"You are an expert in '{main_domain}', specifically focusing on '{sub_domain}'. \"\n",
    "        f\"Provide a detailed, step-by-step solution to the following problem:\\n\\n\"\n",
    "        f\"### Problem:\\n{problem}\"\n",
    "    )\n",
    "    \n",
    "    # Sestavení finálního textu pro trénink\n",
    "    return f\"[INST] {instruction} [/INST] {solution}\"\n",
    "\n",
    "print(\"Příklad naformátovaného promptu:\")\n",
    "print(format_prompt_with_context(dataset[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítám model z lokální cesty: /home/luk-hrd/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Konfigurace a načtení modelu a tokenizeru ---\n",
    "\n",
    "# Konfigurace 4-bitové kvantizace pro úsporu VRAM\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Používá pokročilejší typ kvantizace \"NormalFloat 4\"\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Pro výpočty použije bfloat16 (vyžaduje Ampere GPU nebo novější)\n",
    "    bnb_4bit_use_double_quant=True,  # Mírně zvyšuje úsporu paměti\n",
    ")\n",
    "\n",
    "# Načtení modelu s kvantizací\n",
    "print(f\"Načítám model z lokální cesty: {MODEL_PATH}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Automaticky rozmístí model na dostupné GPU\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.config.use_cache = False  # Vypnutí cache je nutné pro trénink s LoRA\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Načtení tokenizeru\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "# Mistral nemá pad_token, nastavíme ho na end-of-sequence token. To je standardní postup.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  # Důležité pro kauzální modely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Konfigurace PEFT (LoRA) ---\n",
    "\n",
    "# Konfigurace LoRA adaptérů\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank: počet trénovatelných parametrů. 64 je silná hodnota.\n",
    "    lora_alpha=32,  # Škálovací faktor. Obvykle 2*r nebo r/2.\n",
    "    lora_dropout=0.1,  # Dropout pro regularizaci LoRA vah.\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # Cílové moduly specifické pro Mistral-7B. Cílíme na attention vrstvy.\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zahajuji fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [644/644 2:18:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.712900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.572200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.492700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.379700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.417800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.353300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.323100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.282200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.331500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning byl úspěšně dokončen.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Nastavení a spuštění tréninku ---\n",
    "\n",
    "# Vyladěné trénovací argumenty\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=NEW_MODEL_NAME,\n",
    "    num_train_epochs=1,  # 1 epocha je často dostatečná pro fine-tuning, aby se předešlo overfittingu\n",
    "    per_device_train_batch_size=1,  # Upravte podle VRAM vaší GPU (snižte, pokud dochází paměť)\n",
    "    gradient_accumulation_steps=8,  # Efektivní batch size bude 4 * 2 = 8. Pomáhá stabilizovat trénink.\n",
    "    gradient_checkpointing=True, \n",
    "    optim=\"paged_adamw_32bit\",  # Paměťově efektivní optimalizátor od bitsandbytes\n",
    "    save_steps=50,  # Ukládat checkpoint každých 50 kroků\n",
    "    logging_steps=10,  # Logovat metriky (např. loss) každých 10 kroků\n",
    "    learning_rate=2e-4,  # Osvědčená hodnota pro LoRA fine-tuning\n",
    "    weight_decay=0.001,\n",
    "    bf16=True,  # Použít bfloat16 (pokud máte starší GPU bez podpory bfloat16, změňte na fp16=True)\n",
    "    max_grad_norm=0.3,  # Prevence explodujících gradientů\n",
    "    max_steps=-1,  # -1 znamená, že se řídíme počtem epoch\n",
    "    warmup_ratio=0.03,  # Pomalý náběh learning rate pro stabilitu\n",
    "    group_by_length=True,  # Seskupuje texty podobné délky, což výrazně zrychluje trénink\n",
    "    lr_scheduler_type=\"cosine\",  # 'cosine' scheduler často dává lepší výsledky než 'constant'\n",
    "    report_to=\"tensorboard\", # Můžete vizualizovat loss v TensorBoardu\n",
    ")\n",
    "\n",
    "# Vytvoření instance SFTTrainer (Supervised Fine-tuning Trainer)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=format_prompt_with_context,  # Klíčové: používáme naši vylepšenou funkci\n",
    "    #max_seq_length=1024,  # Maximální délka sekvence. Ořízne delší texty.\n",
    "    #tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "# --- Spuštění tréninku ---\n",
    "print(\"Zahajuji fine-tuning...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tuning byl úspěšně dokončen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vyladěný model (LoRA adaptér) byl uložen do: mistral-7b-quantum-instruct-v1/final_adapter\n"
     ]
    }
   ],
   "source": [
    "# --- Uložení finálního modelu ---\n",
    "# Uloží se pouze LoRA adaptér, nikoli celý model.\n",
    "final_output_dir = os.path.join(NEW_MODEL_NAME, \"final_adapter\")\n",
    "trainer.save_model(final_output_dir)\n",
    "print(f\"Vyladěný model (LoRA adaptér) byl uložen do: {final_output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
