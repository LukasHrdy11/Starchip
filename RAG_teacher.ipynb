{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37cbd68",
   "metadata": {},
   "source": [
    "# Propojení RAG databáze s fine-tuned modelem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- KONFIGURACE (z předchozích kroků) ---\n",
    "BASE_MODEL_PATH = \"mistralai/Mistral-7B-Instruct-v0.2\" \n",
    "ADAPTER_PATH = \"./results/checkpoint-400\" # Cesta k vašemu fine-tunovanému adaptéru\n",
    "PERSIST_DB_DIR = \"./rag_db\"\n",
    "EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Načtení jazykového modelu (stejně jako v chat.py)\n",
    "# ---------------------------------------------------\n",
    "print(\"Načítám jazykový model (LLM)...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH, quantization_config=bnb_config, device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "print(\" LLM úspěšně načten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Načtení vektorové databáze\n",
    "# ----------------------------\n",
    "print(\"Načítám vektorovou databázi...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME, model_kwargs={'device': device}\n",
    ")\n",
    "db = Chroma(persist_directory=PERSIST_DB_DIR, embedding_function=embeddings)\n",
    "print(\"✅ Databáze úspěšně načtena.\")\n",
    "\n",
    "# Vytvoření RAG řetězce\n",
    "\n",
    "# Vytvoření text-generation pipeline\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Vytvoření retrieveru z databáze\n",
    "# Tento objekt bude zodpovědný za vyhledávání v databázi\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4}) # Chceme 4 nejrelevantnější chunky\n",
    "\n",
    "# Vytvoření finálního RAG řetězce (chain)\n",
    "# \"stuff\" je jednoduchá metoda, která vezme nalezené chunky a vloží je do promptu\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True # Chceme vidět, z jakých zdrojů model čerpal\n",
    ")\n",
    "\n",
    "print(\" RAG řetězec je připraven k použití.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Položte zde svůj dotaz ---\n",
    "query = \"Jaké jsou hlavní postuláty kvantové mechaniky?\" \n",
    "print(f\"Pokládám dotaz: {query}\\n\")\n",
    "\n",
    "# Spuštění řetězce\n",
    "result = qa_chain(query)\n",
    "\n",
    "# --- Zobrazení výsledků ---\n",
    "print(\"Odpověď modelu:\")\n",
    "print(\"-\" * 50)\n",
    "print(result['result'].strip())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nZdroje použité pro odpověď:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\" - Soubor: {doc.metadata.get('source', 'N/A')}, Strana: {doc.metadata.get('page', 'N/A')}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
